{
 "metadata": {
  "name": "",
  "signature": "sha256:ac1cf9530ec02d267c5b7295f80218d9902d7bf8670078467007f005a7e9e240"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import xmltodict\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "import lxml\n",
      "import re\n",
      "import sys\n",
      "reload(sys)\n",
      "sys.setdefaultencoding(\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_txt(url):\n",
      "    \"\"\"\n",
      "    Grab text from url\n",
      "    \n",
      "    INPUT\n",
      "    url of text/xml data\n",
      "    \n",
      "    OUTPUT\n",
      "    text/xml data\n",
      "        \n",
      "    \"\"\"\n",
      "    # load txt\n",
      "    fp = urllib.urlopen(url)\n",
      "    text = fp.read()\n",
      "    fp.close()\n",
      "    \n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def edit_Joint_Committee(item):\n",
      "    \"\"\"\n",
      "    Dealing with Joint Committee reports\n",
      "    (esp from the Joint Legislative Audit Committee)\n",
      "    \n",
      "    In the future, check that the information skipped is reasonable\n",
      "    \n",
      "    INPUT\n",
      "    item, the list of OrderedDicts with metadata on each committee\n",
      "    Parameters and example data:\n",
      "        (u'guid', OrderedDict([(u'@isPermaLink', u'false'), ('#text', u'5b7a05a6-a615-4dd9-94d6-7346f51a1363')]))\n",
      "        (u'link', u'http://docs.legis.wisconsin.gov/document/committee/2015/1475')\n",
      "        (u'title', u'University of Wisconsin Hospitals and Clinics Authority - 2016-12-17')\n",
      "        (u'description', u'University of Wisconsin Hospitals and Clinics Authority')\n",
      "        (u'pubDate', u'Sat, 17 Dec 2016 07:35:58 -0600')\n",
      "        (u'a10:updated', u'2016-12-17T07:35:58-06:00')\n",
      "    \n",
      "    OUTPUT\n",
      "    boolean, if data will be used\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    OtherJointCommitteeCrap = 'records'\n",
      "    AnnoyingJointCommittees = ['Presentation', 'Report', 'Proceedings', \n",
      "                               'Minutes', 'Proposed', 'Audio', 'Agenda']\n",
      "    \n",
      "    name = item['description']\n",
      "    title = item['title']\n",
      "\n",
      "    if not name: \n",
      "        return False\n",
      "    \n",
      "    if OtherJointCommitteeCrap in name:\n",
      "        return False\n",
      "    \n",
      "    for ajc in AnnoyingJointCommittees:\n",
      "        if ajc in title:\n",
      "            return False\n",
      "    \n",
      "    return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_committee_metadata(text, committee_type):\n",
      "    \"\"\"\n",
      "    Get metadata for committees\n",
      "    \n",
      "    INPUT\n",
      "    text from load_txt(url)\n",
      "    committee_type\n",
      "    \n",
      "    INTERMEDIARIES\n",
      "    x is a list of items/OrderedDicts with metadata on each committee\n",
      "    Parameters and example data:\n",
      "        (u'guid', OrderedDict([(u'@isPermaLink', u'false'), ('#text', u'5b7a05a6-a615-4dd9-94d6-7346f51a1363')]))\n",
      "        (u'link', u'http://docs.legis.wisconsin.gov/document/committee/2015/1475')\n",
      "        (u'title', u'University of Wisconsin Hospitals and Clinics Authority - 2016-12-17')\n",
      "        (u'description', u'University of Wisconsin Hospitals and Clinics Authority')\n",
      "        (u'pubDate', u'Sat, 17 Dec 2016 07:35:58 -0600')\n",
      "        (u'a10:updated', u'2016-12-17T07:35:58-06:00')\n",
      "    \n",
      "    OUTPUT\n",
      "    data, [name, committee_type, link]\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    # x is a list of OrderedDict\n",
      "    # should do some error catching here\n",
      "    # find format of data through testing / pretty xml\n",
      "    x = xmltodict.parse(text)['rss']['channel']['item']\n",
      "    \n",
      "    # iterate for relevant information\n",
      "    data = []\n",
      "    for item in x:\n",
      "        name = item['description']\n",
      "        \n",
      "        interest = True\n",
      "        if not name: \n",
      "            interest = False\n",
      "        \n",
      "        # dealing with Joint Committee reports\n",
      "        if committee_type == 'Joint':\n",
      "            interest = edit_Joint_Committee(item)\n",
      "        \n",
      "        # add to data\n",
      "        if interest:\n",
      "            data.append([name, committee_type, item['link']])\n",
      "    \n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def edit_committee_info(info):\n",
      "    \"\"\"\n",
      "    String editing to get committee info\n",
      "    Reduce text data from each parsed committee site\n",
      "    \n",
      "    INPUT\n",
      "    info, text from get_committee_metadata()\n",
      "    \n",
      "    OUTPUT\n",
      "    data, extrated from info\n",
      "        [header, Chair, CoChair, ViceChair, \n",
      "         CommitteeClerk, LegislativeCouncilStaff, \n",
      "         Member, Other, hearings]\n",
      "    \n",
      "    TO DO\n",
      "    Look into exceptions for names when adding spaces before capital letters \n",
      "    This info doesn't include Hearing Documents/In/Out/All/Proposals\n",
      "    Can also clean this up a little bit\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    # name exceptions?\n",
      "    names = ['VanderMeer', 'Bowers2']\n",
      "    \n",
      "    # rm header\n",
      "    a = info.split('Notify', 1)[-1].lstrip().rstrip()\n",
      "    \n",
      "    # add space before every CAP preceded by ')' or '[a-z]' or '2' but NOT '\\n', ' ' or '-'\n",
      "    #b = re.sub(r'([a-z][a-z|\\)])([A-Z])', r'\\1\\n\\2', a)\n",
      "    # first expression failed to exclude Rep. VanderMeer\n",
      "    # https://regex101.com/r/XS0OC5/1\n",
      "    b = re.sub(r'(?!VanderM)([A-Z|\\(]\\w+[a-z|\\)|2])([A-Z])', r'\\1\\n\\2', a)\n",
      "    \n",
      "    # add space before '(' - rare\n",
      "    # eg for clerk phone number\n",
      "    c = re.sub(r'([a-z])\\(', r'\\1 (', b)\n",
      "    \n",
      "    # replace '\\r\\n ' to '\\n'\n",
      "    d = re.sub(r'\\r\\n +', '\\n', c)\n",
      "    \n",
      "    # lots of spaces to one\n",
      "    e = re.sub(' +', ' ', d)\n",
      "    \n",
      "    # split off hearings\n",
      "    hearings = None\n",
      "    f = e.split('Hearing Notices')\n",
      "    if len(f) == 1: f = f[0]\n",
      "    elif len(f) == 2:\n",
      "        f, hearings = f\n",
      "        hearings = hearings.lstrip().split(' \\n\\n\\n\\n')\n",
      "    else:\n",
      "        print 'WARNING, get_data.edit_committee_info() split info into 3+ parts.'\n",
      "        print info, '\\n'\n",
      "    \n",
      "    # split into headers/chairs/staff/etc, _, members\n",
      "    g, _, members = f.split('Members')\n",
      "    \n",
      "    # split into header/persons\n",
      "    header, persons = [None] * 2\n",
      "    h = filter(None, g.lstrip().rstrip().split('\\n\\n'))\n",
      "    if h:\n",
      "        persons = h.pop()\n",
      "        if h:\n",
      "            header = ' '.join([i.lstrip() for i in h])\n",
      "    \n",
      "    # split persons \n",
      "    Chair, CoChair, ViceChair = [], [], []\n",
      "    CommitteeClerk, LegislativeCouncilStaff = [], []\n",
      "    prev = None\n",
      "    if persons:\n",
      "        lines = persons.split('\\n')\n",
      "        for i, line in enumerate(lines):\n",
      "            if not line: continue\n",
      "            \n",
      "            # Chair\n",
      "            a = line.split(' (Chair)')\n",
      "            if len(a) == 2:\n",
      "                Chair.append(a[0])\n",
      "                prev = Chair\n",
      "                continue\n",
      "            \n",
      "            # CoChair\n",
      "            a = line.split(' (Co-Chair)')\n",
      "            if len(a) == 2:\n",
      "                CoChair.append(a[0])\n",
      "                prev = CoChair\n",
      "                continue\n",
      "            \n",
      "            # ViceChair\n",
      "            a = line.split(' (Vice-Chair)')\n",
      "            if len(a) == 2:\n",
      "                ViceChair.append(a[0])\n",
      "                prev = ViceChair\n",
      "                continue\n",
      "            \n",
      "            # CommitteeClerk\n",
      "            a = line.split('Committee Clerk ')\n",
      "            if len(a) == 2:\n",
      "                CommitteeClerk.append(a[1])\n",
      "                prev = CommitteeClerk\n",
      "                continue\n",
      "            \n",
      "            # LegislativeCouncilStaff\n",
      "            a = line.split('Legislative Council Staff ')\n",
      "            if len(a) == 2:\n",
      "                LegislativeCouncilStaff.append(a[1])\n",
      "                prev = LegislativeCouncilStaff\n",
      "                continue\n",
      "            \n",
      "            # repeat name with no tag\n",
      "            prev.append(a[0].lstrip())\n",
      "\n",
      "    # parse members\n",
      "    Member, Other = [], []\n",
      "    lines = members.split('\\n')\n",
      "    for i, line in enumerate(lines):\n",
      "        if not line: continue\n",
      "        \n",
      "        # Chair\n",
      "        a = line.split(' (Chair)')\n",
      "        if len(a) == 2:\n",
      "            Chair.append(a[0])\n",
      "            continue\n",
      "\n",
      "        # CoChair\n",
      "        a = line.split(' (Co-Chair)')\n",
      "        if len(a) == 2:\n",
      "            CoChair.append(a[0])\n",
      "            continue\n",
      "\n",
      "        # ViceChair\n",
      "        a = line.split(' (Vice-Chair)')\n",
      "        if len(a) == 2:\n",
      "            ViceChair.append(a[0])\n",
      "            continue\n",
      "        \n",
      "        # Other\n",
      "        if line.startswith(' '):\n",
      "            Other.append(line.lstrip())\n",
      "        \n",
      "        # Member\n",
      "        Member.append(line)\n",
      "    \n",
      "    data =  [header, Chair, CoChair, ViceChair, \n",
      "             CommitteeClerk, LegislativeCouncilStaff, \n",
      "             Member, Other, hearings]\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_committee_info(metadata):\n",
      "    \"\"\"\n",
      "    Follow individual links in committee metadata for individual committee info\n",
      "    \n",
      "    INPUT\n",
      "    metadata from get_committee_metadata(), list of str [name, committee_type, url]\n",
      "    \n",
      "    INTERMEDIARIES\n",
      "    info is <class 'bs4.element.Tag'>\n",
      "        Parsed HTML from <div class=\"span5\">\n",
      "            I think all the info that we would want is from this <div>\n",
      "        Andy should check output\n",
      "        Should we use the html tags for other links? Seems like a lot of work.\n",
      "    cominfo is from edit_committee_info()\n",
      "        list of header, people+positions, hearing dates\n",
      "    \n",
      "    OUTPUT\n",
      "    data, [name, committee_type, link, header, \n",
      "           Chair, CoChair, ViceChair, CommitteeClerk, LegislativeCouncilStaff, \n",
      "           Member, Other, hearings]\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    data = []\n",
      "    for meta in metadata:\n",
      "        # parse html\n",
      "        name, committee_type, url = meta\n",
      "        text = load_txt(url)\n",
      "        parser = BeautifulSoup(text, \"lxml\")\n",
      "        info = parser.body.find('div', attrs={'class':'span5'})\n",
      "        \n",
      "        # retrieve committee info\n",
      "        cominfo = [None, [], [], [], [], [], [], [], []]\n",
      "        if info:\n",
      "            # header, Chair, CoChair, ViceChair, CommitteeClerk, LegislativeCouncilStaff, Member, Other, hearings\n",
      "            cominfo = edit_committee_info(info.text)\n",
      "        tmp = meta + cominfo\n",
      "        data.append(tmp)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_committee(out = 'committees.csv'):\n",
      "    \"\"\"\n",
      "    Get all data for committees\n",
      "    \n",
      "    INPUT\n",
      "    out the output file\n",
      "    \n",
      "    SAVE TO FILE out\n",
      "    data\n",
      "        [name, committee_type, link, header, \n",
      "         Chair, CoChair, ViceChair, CommitteeClerk, LegislativeCouncilStaff, \n",
      "         Member, Other, hearings]\n",
      "    \n",
      "    SAVE TO FILE committee_list.txt\n",
      "    names of all the committees\n",
      "    \n",
      "    TO DO\n",
      "    Follow more links? Get more research done here, as I've skipped links for ease.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    root = 'http://docs.legis.wisconsin.gov/feed/2015/committees/'\n",
      "    committee_type = ['Senate', 'Assembly', 'Joint', 'Other']\n",
      "    #committee_type = ['Senate']\n",
      "    \n",
      "    data = []\n",
      "    for ct in committee_type:\n",
      "        # metadata\n",
      "        # [committee name, committee_type, link]\n",
      "        text = load_txt(root+ct)\n",
      "        metadata = get_committee_metadata(text, ct)\n",
      "        \n",
      "        # other data\n",
      "        infodata = get_committee_info(metadata)\n",
      "        \n",
      "        # add to data\n",
      "        data.extend(infodata)\n",
      "        \n",
      "    # save list of committees to file\n",
      "    with open('committee_list.txt', 'w') as f:\n",
      "        for d in data:\n",
      "            f.write(d[0] + '\\n')\n",
      "    \n",
      "    # write list of lists to outfile\n",
      "    header = ['CommitteeName', 'CommitteeType', 'URL', 'Header', 'Chair', 'CoChair', 'ViceChair', \n",
      "              'CommitteeClerk', 'LegislativeCouncilStaff', 'Members', 'OtherMembers', 'Hearings']\n",
      "    with open(out, 'w') as f:\n",
      "        writer = csv.writer(f)\n",
      "        writer.writerow(header)\n",
      "        writer.writerows(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_committee()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}